WEBVTT
Kind: captions
Language: zh-CN

00:00:00.072 --> 00:00:03.351
我最后讲解的内容是 为什么普通的隐马尔可夫模型公式

00:00:03.351 --> 00:00:04.910
不能很好地生成数据

00:00:04.910 --> 00:00:08.375
在语音识别早期 人们希望

00:00:08.375 --> 00:00:12.431
我们可以使用相同的隐马尔可夫模型识别语音 也生成数据

00:00:12.430 --> 00:00:13.702
结果说明这种观点并不好

00:00:13.702 --> 00:00:16.096
即使后期发展产生较好的结果

00:00:16.096 --> 00:00:18.835
— 也许例子可以最好说明这个问题

00:00:18.835 --> 00:00:19.539
— 没错

00:00:19.539 --> 00:00:22.521
我们采用这节课开头相同的隐马尔可夫模型

00:00:22.521 --> 00:00:24.387
— 这个模拟游离线的模型吗？

00:00:24.388 --> 00:00:28.719
— 没错 现在观察这个隐马尔可夫模型 而不是样本数据

00:00:28.719 --> 00:00:33.148
给我第一个状态可以生成的 10 个数字

00:00:33.148 --> 00:00:37.711
— 好 -1 -1 -2 -1.5

00:00:37.710 --> 00:00:42.957
-1 -1.25 -1.75 和 -2

00:00:42.957 --> 00:00:44.586
— 第二个状态中的一些数字

00:00:44.587 --> 00:00:50.598
—  0 -0.5 -0.25 -0.75 和 -1

00:00:50.597 --> 00:00:52.554
— 第三个状态也是相同的做法

00:00:52.554 --> 00:00:57.417
— 1 0 1 1 0 1 1 1 0 1 0

00:00:57.417 --> 00:01:00.968
0 1 0 0 1 0 1 0

00:01:00.968 --> 00:01:02.629
— 然后是最后状态

00:01:02.628 --> 00:01:06.376
— 1.5 1.75 和 1

00:01:06.376 --> 00:01:09.548
— 对这些数字的绘图看起来不像初始的例子

00:01:09.549 --> 00:01:11.947
因为输出分布不具有连续性

00:01:11.947 --> 00:01:14.007
— 我们如何调整呢？

00:01:14.007 --> 00:01:17.304
— 我们可以使用许多状态 形成输出更好的排序

00:01:17.304 --> 00:01:20.189
但是可能会导致过度拟合

00:01:20.189 --> 00:01:23.057
更好的办法是在一个隐马尔可夫模型中模拟状态转移

00:01:23.058 --> 00:01:26.402
不过在更加了解语境的每个状态中 生成最终数据时

00:01:26.402 --> 00:01:28.960
使用不同的过程

00:01:28.959 --> 00:01:30.920
这里有些可以使用的方法

00:01:30.921 --> 00:01:34.999
但是我知道最复杂的是语音合成研究人员的工作

00:01:34.998 --> 00:01:38.537
例如谷歌拥有一些优质文档 说明如何把隐马尔可夫模型和

00:01:38.537 --> 00:01:40.909
深层信度网络结合起来 得到更好的结果

