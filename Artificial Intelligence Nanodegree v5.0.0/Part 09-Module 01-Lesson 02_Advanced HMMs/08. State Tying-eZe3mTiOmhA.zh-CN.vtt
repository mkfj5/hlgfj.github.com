WEBVTT
Kind: captions
Language: zh-CN

00:00:00.250 --> 00:00:02.008
另一个技巧是状态绑定

00:00:02.008 --> 00:00:03.269
— 你是说把状态训练和

00:00:03.270 --> 00:00:05.910
模型中的状态组合起来是闭合的吗？

00:00:05.910 --> 00:00:06.309
— 没错

00:00:06.309 --> 00:00:08.432
我们再次来观察模型 I 和 we

00:00:08.432 --> 00:00:13.409
在我们识别孤立手势的情况中 右手靠近胸部的初始动作

00:00:13.409 --> 00:00:18.789
在两个模型中是类似的

00:00:18.789 --> 00:00:23.530
除了包括模型 I 和 we 的状态 1

00:00:23.530 --> 00:00:28.950
我们都有初始状态 定义 I 和 we 这样两个模型都可以包括它

00:00:28.949 --> 00:00:33.159
我们训练隐马尔可夫模型的方式 我们拥有两倍的数据

00:00:33.159 --> 00:00:35.289
来训练初始状态

00:00:35.289 --> 00:00:38.579
— 我们对最终状态采用相同操作 因为

00:00:38.579 --> 00:00:42.979
手放回原来位置 看起来与 I 和 we 孤立模型相同

00:00:42.979 --> 00:00:45.689
— 我们使用这个技巧非常小心

00:00:45.689 --> 00:00:48.817
因为我们开始担心语境训练时 状态绑定变得复杂起来

00:00:48.817 --> 00:00:52.979
对于新表格和 we want CAT2 唯一应该绑定的状态

00:00:52.979 --> 00:00:57.269
模型 I 和 we 的第一个状态和 table 与 cat 的最后状态

00:00:57.270 --> 00:01:01.200
— 这甚至不算是 table 与 CAT2 的最后状态 如果我们使用更多特征

00:01:01.200 --> 00:01:05.560
‘而不只是 Δy 那么table 与 CAT2 的最后状态会截然不同

00:01:05.560 --> 00:01:08.240
— 说的不错 实际上我经常寻找

00:01:08.239 --> 00:01:11.649
在训练中包含封闭均值和方差

00:01:11.650 --> 00:01:15.530
并且根据我期望的动作 决定绑定它们是否符合逻辑

00:01:15.530 --> 00:01:18.450
这种情况下 数据的视觉化和

00:01:18.450 --> 00:01:20.719
迭代有利于完善我们的结果

